---
format:
  revealjs:
    auto-stretch: false
    margin: 0
    slide-number: true
    scrollable: true
    preview-links: auto
    page-layout: custom
    logo: imagenes/logo_portada2.png
    css: ine_quarto_styles.css
    chalkboard: 
      boardmarker-width: 20
      buttons: false
    # footer: <https://quarto.org>
engine: knitr
---

#


[]{.linea-superior} 
[]{.linea-inferior} 

<!---
 <img src="imagenes/logo_portada2.png" style="width: 20%"/>  
--->

<img src="imagenes/logo_portada2.png" width="20%"/>  


[**Modelo de detecci칩n de objetos YOLO**]{.big-par .center-justified}

[**Proyecto Ciencia de Datos**]{.medium-par.center-justified}

[**Unidad de Gobierno de Datos**]{.small-par.center-justified}

[**Diciembre 2024**]{.big-par .center-justified}



<!-- descripci칩n de las cosas que se hacen con yolo -->
<!-- mostrar la variedad de modelos yolo que existen -->
<!-- arquitectura:  -->
<!-- - 쮺omo se compone? 쯈ue ocurre en cada una de esos ejes: Neck, BackBones, Head? -->
<!-- - comentar algunas partes de inter칠s en cada una de esos ejes como el feature map, data augmentation etc -> que descomposiciones se debe realizar para que logremos capturar la imagen (procesamiento del input, muy a grandes rasgos (Neck)) -->

<!-- Performance (medidas) -->

<!-- mostrar el ejemplito de comparaci칩n entre versiones yolo -->

<!-- modelo YOLO-World ->  -->


## Contenidos  

::: {.medium-par}

- Problema de detecci칩n de objetos 游뱂
  
  - Contexto 
  - Historia: Ventanas deslizantes y R-CNN

- 쯈u칠 es YOLO? 游뱄
  
  - Arquitectura
  
  - Versiones
  
- Modelo YOLO-World 游깵
  
- Conclusiones 游

- Referencias 

:::

## Problema de detecci칩n de objetos (1/8)


[Miremos nuestro alrededor 쯖u치ntos objetos pueden identificar?]{.center .big-par}


[<img src="imagenes/plots/lupa.png" width="20%"/>]{.center} 

. . .

<!-- Los humanos, podemos reconocer objetos en im치genes en milisegundos. Miramos toda la imagen, entendemos el contexto, y sabemos que un objeto es x porque z y no flotando en el aire. Pero las computadoras no tienen esa intuici칩n. Necesitan que les demos reglas claras para identificar qu칠 est치n viendo y d칩nde lo est치n viendo -->

[쮺칩mo le ense침amos a una m치quina no solo a reconocer objetos, sino a decirnos exactamente d칩nde est치n?]{.center .big-par}

## Problema de detecci칩n de objetos (2/8)

::: {.incremental .medium-par}

- Uno de los primeros enfoques que abordaron esta problem치tica son las *ventanas deslizantes*

- Consiste en mover sistem치ticamente una ventana de tama침o fijo a lo largo de una imagen (d x d pixeles) y clasificar el objeto dentro de la ventana utilizando una red de clasificaci칩n.

    [<img src="imagenes/plots/ventana_deslizante.PNG" width="60%"/>]{.center} 

:::


## Problema de detecci칩n de objetos (3/8)

Primera iteraci칩n: 

[<img src="imagenes/plots/ventana_deslizante1.PNG" width="70%"/>]{.center} 

[<img src="imagenes/plots/ventana_deslizante2.PNG" width="70%"/>]{.center} 


## Problema de detecci칩n de objetos (4/8)

Segunda iteraci칩n: 

[<img src="imagenes/plots/ventana_deslizante3.PNG" width="70%"/>]{.center} 

[<img src="imagenes/plots/ventana_deslizante4.PNG" width="70%"/>]{.center} 


## Problema de detecci칩n de objetos (5/8)

[<img src="imagenes/plots/ventana_deslizante5.PNG" width="70%"/>]{.center} 

:::{.incremental .medium-par}

- 쯈u칠 pasa si un mismo objeto es detectado m치s de una vez?

- 쮺칩mo definimos el tama침o de nuestra ventana?

- 쮺uanto muevo mi ventana?

- 쮼fectivamente mi objeto est치 en esas coordenadas?

:::

<!-- No obtenemos directamente las coordenadas exctas de nuestra imagen -->
<!-- Proceso computacionalmente muy costoso -->


## Problema de detecci칩n de objetos (6/8)

:::{.incremental .medium-par}

- A partir de esto, nace la idea de quedarnos con zonas que posiblemente tengan objetos
    
    [<img src="imagenes/plots/perro_gato_identif.PNG" width="50%"/>]{.center} 
    
::: 

## Problema de detecci칩n de objetos (7/8)

:::{.incremental .medium-par}

- Redes neuronales convolucionales basadas en regiones *R-CNN* (2014)

    [<img src="imagenes/plots/rcnn.PNG" width=90%"/>]{.center} 

- Se determinan regiones propuestas en donde posiblemente existen objetos

- Lo que nos ayuda a reducir la cantidad de ventanas a clasificar

- Estas propuestas de regiones se pueden seleccionar mediante la extracci칩n de bordes, texturas, puntos caracter칤sticos etc.

::: 

## Problema de detecci칩n de objetos (8/8)

:::{.incremental .medium-par}

- Si bien reducimos la cantidad de ventanas, sigue siendo lento para la detecci칩n en tiempo real

- Con las R-CNN continuamos procesando cada regi칩n por separado, lo que implica perdida del contexto de la imagen

::: 

. . .

[쯇or qu칠 no miramos toda la imagen de una vez?游뱂]{.center} 

## 쯈u칠 es YOLO? (1/3)

:::{.incremental .medium-par}

- Se propone You Only Look Once; solo se ve una vez. 

- Se observa toda la imagen y detectamos los objetos simult치neamente.

    [<img src="imagenes/plots/yolo1.PNG" width=90%"/>]{.center} 
    
- 쯊rabajar directamente con toda la imagen no es computacionalmente m치s costo?
  
  - Se realiza un downsampling, el cual reduce progresivamente el tama침o de las caracter칤sticas de la imagen sin perder informaci칩n relevante, haciendo que el modelo sea m치s eficiente.
  
  - A medida que la resoluci칩n disminuye, la red profundiza su entendimiento, analizando desde detalles finos (bordes) hasta patrones globales (formas completas).
  
:::




<!-- - Trabajar directamente con im치genes grandes ser칤a computacionalmente costoso, tanto en t칠rminos de memoria como de tiempo. -->


<!-- Stride en las convoluciones: -->
<!-- Cada capa convolucional tiene un "stride" que controla cu치nto se reduce la imagen en cada paso. -->

<!-- Ejemplo: Un stride de 2 reduce las dimensiones de la imagen a la mitad. -->
<!-- Pooling: -->
<!-- Operaciones como max pooling resumen regiones de la imagen seleccionando el valor m치s relevante (m치ximo). -->

<!-- An치lisis jer치rquico: -->
<!-- A medida que la resoluci칩n disminuye, la red profundiza su entendimiento, analizando desde detalles finos (bordes) hasta patrones globales (formas completas). -->



## 쯈u칠 es YOLO? (2/3)

:::{.incremental .medium-par}

- Para ello, se divide la imagen en cuadriculas (SxS), en donde cada celda es responsable de detectar objetos que caigan dentro su regi칩n

    [<img src="imagenes/plots/yolo2.PNG" width=70%"/>]{.center} 


- Se realiza la predicci칩n en cada celda, 쯘xiste un objeto aqu칤? 쯖u치l? -> retorna las coordenadas

- Posteriormente se realiza una limpieza de celdas *Non-Max Suppression*
  
  <!-- 1. Eliminar los bounding box que tengan una probabilidad menor a un umbral -->

  <!-- 2. De los bounding boxing restantes, se toma el valor mayor predicci칩n -->

  <!-- 3. Se calcula el IoU entre el bounding box mayor con los dem치s -->

  <!-- 4. Si el IoU es mayor a cierto umbral, entonces vamos a descartarlos pues ya est치n siendo explicados por la mayor predicci칩n -->

  <!-- 5. Iterar los pasos 2 al 4 -->
  
  <!-- IoU: Intersecci칩n sobre la uni칩n Inter/Uni칩n -> para ver que tan buena es la predicci칩n -->
::: 

## 쯈u칠 es YOLO? (3/3)

:::{.incremental .medium-par}

- Para entrenar al modelo, muy a grandes rasgos:

    [<img src="imagenes/plots/yolo3.PNG" width=70%"/>]{.center} 

:::





<!-- - Pasamos toda la informaci칩n de la imagen por la red y obtenemos las coordenadas con sus clases correspondientes para cada objeto -->




<!-- YOLO: -->
<!--   - Dividir imagen, se divide en cuadriculas (SxS), en donde cada celda es responsable de detectar objetos que caigan dentro de la region -->
<!--   - Predicci칩n en cada celda, 쮼xiste un objeto aqui? 쯖u치l? -> retorna las coordenadas -->
<!--   - Limpieza de los Bounding Boxes, las celdas cercanas pueden predecir el mismo objeto con peque침as diferencias -> se eliminan las predicciones supuestas descartando las menos confiables con Non-Maximum Suppression -->





<!-- ## Comparaci칩n YOLO vs M칠todos Anteriores -->
<!-- Velocidad: -->

<!-- R-CNN procesa regiones por separado; YOLO procesa todo de una vez. -->
<!-- Resultado: YOLO es significativamente m치s r치pido. -->
<!-- Precisi칩n: -->

<!-- Los modelos anteriores no usan el contexto global de la imagen; YOLO s칤. -->
<!-- Resultado: Mejor detecci칩n en escenarios complejos (como objetos solapados). -->
<!-- Simplicidad: -->

<!-- YOLO convierte la detecci칩n de objetos en un solo problema de regresi칩n. -->
<!-- Resultado: Una arquitectura m치s simple, f치cil de entrenar y m치s eficiente. -->
  
  
<!-- https://blog.damavis.com/reconocimiento-de-objetos-con-deep-learning/ -->
  
<!-- Detecci칩n de objetos con YOLO: implementaciones y como usarlas -->

<!-- https://medium.com/@Data_Aficionado_1083/object-detection-sliding-window-r-cnn-fast-r-cnn-faster-r-cnn-f47c7dbe003d -->


## 쯈u칠 es YOLO? | Arquitectura (1/2)

:::{.incremental .medium-par}

- El modelo consta de una arquitectura de 3 partes principales: Backbone, Neck, Head

    [<img src="imagenes/plots/yolo_struture2.PNG" width=90%"/>]{.center} 

- Backbone: Extrae caracter칤sticas del input (patrones, texturas y bordes) en diferentes niveles de abstracci칩n a un conjunto llamado mapas de caracter칤sticas (feature maps)

- Neck: Organiza y refina estas caracter칤sticas, mejorando la informaci칩n espacial

- Head: Produce las predicciones finales y entrega el bounding box

<!-- - Esta estructura modular es lo que permite la velocidad y precisi칩n de YOLO. -->
:::


<!-- El Backbone "traduce" la imagen original a un conjunto de mapas de caracter칤sticas (feature maps) que representan diferentes niveles de abstracci칩n. -->




## 쯈u칠 es YOLO? | Arquitectura (2/2)

YOLOv5:

[<img src="imagenes/plots/estructura_yolov5.avif" width=70%"/>]{.center} 


## 쯈u칠 es YOLO? | Versiones (1/2)

[<img src="imagenes/plots/yolo_timeline.png" width="90%"/>]{.center}

## 쯈u칠 es YOLO? | Versiones (2/2)

[<img src="imagenes/plots/comparaacion_yolovs.png" width="90%"/>]{.center}

. . .

Para la gran mayor칤a de modelos YOLO existentes no hay papers formales, pero si podemos encontrar documentaci칩n de su uso
  
  [<img src="imagenes/plots/papers.png" width="70%"/>]{.center}


## Modelo YOLO-World (1/2)

:::{.incremental .medium-par}

- Sabemos que para detectar los objetos necesitamos una clase fija, pero 쯣odremos detectar objetos a partir de textos descriptivos? 

  
  > YOLO-World presenta el paradigma prompt-then-detect, *escribo luego detecto*, para una inferencia eficiente basada en el vocabulario del usuario el cual re-parametriza embeddings como par치metros dentro del modelo y logra una velocidad de inferencia *superior*.

    [<img src="imagenes/plots/yolo_world.png" width="90%"/>]{.center}
    
::: 

## Modelo YOLO-World (2/2)

Ejemplos:

. . .

[<img src="imagenes/plots/yolo_world_ex.png" width="90%"/>]{.center}

[<img src="imagenes/plots/yolo_world_ex2.png" width="90%"/>]{.center}


## Conclusiones 游

:::{.incremental .medium-par}

- Como hemos visto, YOLO es un tanque

:::


## Referencias
 

:::{.medium-par}

- [Ultralytics](https://docs.ultralytics.com/models/)

- [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/pdf/1506.02640)

- [YOLOv4: Optimal Speed and Accuracy of Object Detection](https://arxiv.org/pdf/2004.10934v1)

- [YOLOV5, YOLOV8 AND YOLOV10: THE GO-TO DETECTORS FOR REAL-TIME VISION](https://arxiv.org/pdf/2407.02988)

- [YOLO-World: Real-Time Open-Vocabulary Object Detection](https://arxiv.org/pdf/2401.17270)

- [Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524)

<!-- https://www.aprendemachinelearning.com/modelos-de-deteccion-de-objetos/ -->

:::

#


[]{.linea-superior} 
[]{.linea-inferior} 


<img src="imagenes/logo_portada2.png" width="20%"/>  


[**Modelo de detecci칩n de objetos YOLO**]{.big-par .center-justified}

[**Proyecto Ciencia de Datos**]{.medium-par.center-justified}

[**Unidad de Gobierno de Datos**]{.small-par.center-justified}

[**Diciembre 2024**]{.big-par .center-justified}


